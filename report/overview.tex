\chapter{Overview of Optimal Transport}

\myminitoc

Optimal Transport theory aims to define a geometry along with a notion of
distance on the set of probability measures over a space.

\sect{Introduction}

\subs{\textsc{Monge}'s Problem}

The history of optimal transport formulations can be traced back to Gaspard
Monge's \emph{Mémoire sur la théorie des déblais et des remblais (1781)},
studying how to move masses of sand or soil from one place to another. The
main motivation of this \emph{Mémoire} being that we can assign a cost to
the act of moving a massic particle from one place to another, and it is
of particular interest to seek for the most optimal way of moving a global
quantity of mass from one place to another.

\begin{center}
	\begin{tikzpicture}[>=stealth']
		\draw[fill=brown!20] (-1, -1.8) rectangle (9, 0);
		\draw[fill=red, domain=0:2, smooth, variable=\x, fill opacity=0.9]
			plot({1.5*\x}, {\x * (27.21 + \x * (-126.6 + \x * (229.9 + \x * (-200.7
				+ \x * (84.24 - 13.61 * \x)))))}) -- (3.05, 0);
		\node[red] at (-0.2, 0.7) {$\mu$};
		\draw[fill=blue, fill opacity=0.9]
			(5, 0) -- (5.1, -1.2) -- (5.5, -1.2) -- (5.6, -1) -- (5.9, -1) --
			(6, -1.2) -- (6.4, -1.2) -- (6.5, -1) -- (6.8, -1) -- (6.9, -1.2) --
			(7.3, -1.2) -- (7.4, -1) -- (7.7, -1) -- (7.8, 0);
		\node[blue] at (8, -1.2) {$\nu$};
		\draw[ultra thick, purple] (0.4, 0) -- (0.4, 1.68);
		\draw[ultra thick, purple] (6.1, 0) -- (6.1, -1.2);
		\node[red] (x) at (0.4, -0.15) {$\bullet$};
		\node[blue] (y) at (6.1, 0.15) {$\bullet$};
		\node[below] at (x) {$x$};
		\node[above] at (y) {$y = T(x)$};
		\coordinate (y) at (6, 0.1);
		\draw[->, ultra thick, greenTikz, bend right=30]
			(x) edge node[below, black] {${\color{greenTikz}c}(x, T(x))$} (y);
	\end{tikzpicture}
\end{center}

\paragraph{Formalism of Monge's problem}

We work in a probability space $\Omega$. We consider two probability measures
$\mu$ and $\nu$ on $\mathcal{P}(\Omega)$. We also consider a cost function
$c : \Omega \times \Omega \rightarrow \R$. This function can for instance
be the Euclidean distance. Monge's problem is therefore the following

$$ \min_{T: \Omega \to \Omega} \int_{\Omega} c \left( x, T(x) \right) \mu(x) $$
\vspace{-2mm}
$$ \text{s.t.} \quad \forall A \in \mathcal{P}(\Omega), \, \nu(A) = \mu \left( T^{-1}(A) \right) $$

The function $T$ is called a transport map. It carries the information
regarding the displacement of each elementary unit of probability: the
mass located in $x$ is moved toward $T(x)$. The function $c$ thus allows
to quantify the cost of moving one elementary unit of mass. We want to
minimize the average distance travelled by mass units during the optimal
transport. The condition under which the optimization is performed ensures
that all the mass of $\mu$ has been transported toward the distribution $\nu$.

\paragraph{Limitations}

The issue with such a formulation of an optimal transport problem is that
it does not handle discrete probability measures. Indeed, if $\mu$ has a
Dirac impulse bigger than every Dirac impulse of $\nu$, then the transport
map cannot be build: we are only performing displacements of mass, and not
actual repartition of mass.

\subs{Kantorovich's problem}

Kantorovich came up  with an alternative formulation for the optimal
transport problem, aiming to handle discrete distributions.

\begin{center}
	\begin{tikzpicture}[>={latex}, scale=1.2]
		\draw[->, greenTikz, ultra thick] (5.20, 3.65) -- node[black, above] {60} (3.96, 3.47);
		\fill[red] (5.20, 3.65) circle (0.136) node[white] {\tiny 60};
		\fill[blue] (3.65, 3.42) circle (0.313) node[white] {120};
		\draw[->, greenTikz, ultra thick] (6.69, 0.87) -- node[black, above right] {90} (5.21, 1.91);
		\fill[red] (6.69, 0.87) circle (0.221) node[white] {90};
		\fill[blue] (0.33, 0.18) circle (0.221) node[white] {90};
		\draw[->, greenTikz, ultra thick] (3.73, 0.65) -- node[black, left] {60} (3.66, 3.11);
		\draw[->, greenTikz, ultra thick] (3.73, 0.65) -- node[black, above] {90} (0.55, 0.21);
		\fill[red] (3.73, 0.65) circle (0.409) node[white] {150};
		\fill[blue] (5.03, 2.04) circle (0.221) node[white] {90};
		
		\node[red, below] at (5.2, 3.55) {\textbf{1}};
		\node[red, right=6] at (6.69, 0.87) {\textbf{2}};
		\node[red, below right=9] at (3.73, 0.65) {\textbf{3}};
		\node[blue, left=8] at (3.65, 3.42) {\textbf{A}};
		\node[blue, left=6] at (0.33, 0.18) {\textbf{B}};
		\node[blue, above=6] at (5.03, 2.04) {\textbf{C}};
	\end{tikzpicture}
\end{center}

\paragraph{Change of transport plan}
The idea of Kantorovich is to change the function $T : \Omega \rightarrow
\Omega$ into a probability $P$ on the product space $\mathcal{P}(\Omega \times
\Omega)$. On the above example, Monge's formulation forbids to split the
masse of size 150 into two separate masses. With Kantorovich's formulation,
this operation becomes accessible: the mass of $150$ is splitted into a mass
of $90$ and a mass of $60$, both sent to different places. In the discrete
case, we can represent what happens through a matrix.

\begin{center}
	\begin{tikzpicture}[scale=1.15]
		\draw[step=1, thick] (0, 0) grid (3, 3);
		\node at (0.5, 0.5) {\Large $p_{{\color{red}3}{\color{blue}A}}$};
		\node at (1.5, 0.5) {\Large $p_{{\color{red}3}{\color{blue}B}}$};
		\node at (2.5, 0.5) {\Large $p_{{\color{red}3}{\color{blue}C}}$};
		\node at (0.5, 1.5) {\Large $p_{{\color{red}2}{\color{blue}A}}$};
		\node at (1.5, 1.5) {\Large $p_{{\color{red}2}{\color{blue}B}}$};
		\node at (2.5, 1.5) {\Large $p_{{\color{red}2}{\color{blue}C}}$};
		\node at (0.5, 2.5) {\Large $p_{{\color{red}1}{\color{blue}A}}$};
		\node at (1.5, 2.5) {\Large $p_{{\color{red}1}{\color{blue}B}}$};
		\node at (2.5, 2.5) {\Large $p_{{\color{red}1}{\color{blue}C}}$};
		
		\node at (1.5, 3.5) {\large Transport Map};
		\node[blue] at (0.5, -0.5) {\Large 120};
		\node[blue] at (1.5, -0.5) {\Large 90};
		\node[blue] at (2.5, -0.5) {\Large 90};
		\node[red] at (-0.5, 0.5) {\Large 60};
		\node[red] at (-0.5, 1.5) {\Large 90};
		\node[red] at (-0.5, 2.5) {\Large 150};
		
		\node at (7.5, 3.5) {\large Distance matrix};
		\draw[step=1, thick] (6, 0) grid (9, 3);
		\node at (6.5, 0.5) {\Large $d_{{\color{red}3}{\color{blue}A}}$};
		\node at (7.5, 0.5) {\Large $d_{{\color{red}3}{\color{blue}B}}$};
		\node at (8.5, 0.5) {\Large $d_{{\color{red}3}{\color{blue}C}}$};
		\node at (6.5, 1.5) {\Large $d_{{\color{red}2}{\color{blue}A}}$};
		\node at (7.5, 1.5) {\Large $d_{{\color{red}2}{\color{blue}B}}$};
		\node at (8.5, 1.5) {\Large $d_{{\color{red}2}{\color{blue}C}}$};
		\node at (6.5, 2.5) {\Large $d_{{\color{red}1}{\color{blue}A}}$};
		\node at (7.5, 2.5) {\Large $d_{{\color{red}1}{\color{blue}B}}$};
		\node at (8.5, 2.5) {\Large $d_{{\color{red}1}{\color{blue}C}}$};
	\end{tikzpicture}
\end{center}

\paragraph{Discrete Case}

If we denote $D$ the distance matrix of the problem, we obtain the following
formulation in the discrete case:

$$ \min_P \langle P, D \rangle = \sum_i \sum_j p_{ij} d_{ij} $$
\vspace{-4mm}
$$ \text{s.t.} \quad \left\{ \begin{array}{ll}
\forall i & \sum_j p_{ij} = \mu_i \\
\forall j & \sum_i p_{ij} = \nu_j
\end{array} \right. $$

The two conditions encode the fact that we aim to move all the mass of $\mu$
toward all the mass of $\nu$.

\paragraph{Continuous Case}

In the continuous setting, we introduce the following set of joint
probabilities, which encodes the analog of the two conditions in the discrete
case, making sure that $\mu$ has been fully transported to $\nu$.

$$ \Pi(\mu, \nu) = \left\{ P \in \mathcal{P}(\Omega \times \Omega) \mid \forall A, B \in \Omega, \, P(A \times \Omega) = \mu(A), \, P(\Omega \times B) = \nu(B) \right\} $$

We can rephrase the definition of $\Pi(\mu, \nu)$ as being the set of
probability measures on $\Omega \times \Omega)$ with marginals $\mu$ and $\nu$.

We consider once again a cost function $c$ defined as in the Monge's
problem. Kantorovich's formulation now becomes the following optimization
problem, where $X \sim \mu$ and $Y \sim \nu$:

$$ \inf_{P \in \Pi(\mu, \nu)} \E_P \left[ c(X, Y) \right] = \int \int c(x, y) P(dx, dy) $$

\paragraph{Existence of solutions} One can wonder whether solutions of
Kantorovich's problem as formulated above exist. A rich litterature exists
on this topic. For instance, in the case of measures on the $\mathbf{R}^n$
space, with absolutely continuous measures $\mu$ and $\nu$ with respect to
the Lebesgue measure, the existence (and uniqueness) of solutions will then
depend on the properties of the cost function. If we consider the cost
function $c_p(x,y) = | x - y |^p$, then we will have the following discussion:

\begin{itemize}
    \item $p > 1$: the strict convexity of $c_p$ ensures that there is a
    unique solution to the Kantorovich problem
    \item $p = 1$: here we can obtain the existence of a minimizer for the
    Kantorovich, but we won't have the unicity of the solution
    \item $p < 1$: in general, there will not exist solutions to the problem
\end{itemize}

More generally the existence of minimizers, as well as their uniqueness
depends heavily on the structure of the space we consider, and the properties
of both the measures and the cost function. A comprehensive study of those
properties can be found in \cite{villani2003topics}.

\subs{Wasserstein distance}

Having formulated this optimization problem allows us to define a distance
between probability measures.

\DEF{
    Given a probability space $\Omega$, a cost function $c : \Omega \times
    \Omega \rightarrow \R$ and two probabilitiy mesures $\mu$ and $\nu$ in
    $\mathcal{P}(\Omega)$, the \textbf{p-Wasserstein-distance} between $\mu$
    and $\nu$ is defined as:
	$$ W_p(\mu, \nu) = \left( \inf_{P \in \Pi(\mu, \nu)} \int \int c(x,
	y)^p P(dx, dy) \right)^{1 / p} $$
	\vspace{-3mm}
}

This notion of distance allows to compute barycenters between several
probability distributions, and obtain results that are way more natural
than barycenters obtained with other norms, like the $l^2$ norm for
instance. The following figure compares an interpolation (\emph{i.e.}
a progressive weighted barycenter of two distributions) obtained under
Wasserstein-distance and a linear interpolation (the two target distributions
being the blue and the red one, and the purple shape being an intermediate
interpolation).

\begin{center}
	\begin{tikzpicture}[scale=0.85]
		\node at (5.5, 4.5) {\large Linear Interpolation};
		\node[red] at (0.5, 2.3) {$\mu$};
		\node[blue] at (9.5, 2.7) {$\nu$};
		\fill[red] (0.000, 0.000) -- (0.050, 0.403) -- (0.100, 0.752) -- (0.150, 1.051) -- (0.200, 1.302) -- (0.250, 1.509) -- (0.300, 1.676) -- (0.350, 1.806) -- (0.400, 1.902) -- (0.450, 1.967) -- (0.500, 2.004) -- (0.550, 2.016) -- (0.600, 2.006) -- (0.650, 1.976) -- (0.700, 1.929) -- (0.750, 1.868) -- (0.800, 1.794) -- (0.850, 1.710) -- (0.900, 1.618) -- (0.950, 1.521) -- (1.000, 1.419) -- (1.050, 1.315) -- (1.100, 1.211) -- (1.150, 1.108) -- (1.200, 1.008) -- (1.250, 0.912) -- (1.300, 0.822) -- (1.350, 0.738) -- (1.400, 0.662) -- (1.450, 0.595) -- (1.500, 0.537) -- (1.550, 0.490) -- (1.600, 0.455) -- (1.650, 0.431) -- (1.700, 0.419) -- (1.750, 0.420) -- (1.800, 0.435) -- (1.850, 0.462) -- (1.900, 0.503) -- (1.950, 0.556) -- (2.000, 0.623) -- (2.050, 0.703) -- (2.100, 0.796) -- (2.150, 0.900) -- (2.200, 1.017) -- (2.250, 1.144) -- (2.300, 1.281) -- (2.350, 1.428) -- (2.400, 1.584) -- (2.450, 1.746) -- (2.500, 1.915) -- (2.550, 2.089) -- (2.600, 2.267) -- (2.650, 2.447) -- (2.700, 2.627) -- (2.750, 2.807) -- (2.800, 2.984) -- (2.850, 3.156) -- (2.900, 3.321) -- (2.950, 3.478) -- (3.000, 3.624) -- (3.050, 3.757) -- (3.100, 3.874) -- (3.150, 3.973) -- (3.200, 4.052) -- (3.250, 4.107) -- (3.300, 4.136) -- (3.350, 4.137) -- (3.400, 4.105) -- (3.450, 4.038) -- (3.500, 3.933) -- (3.550, 3.787) -- (3.600, 3.595) -- (3.650, 3.355) -- (3.700, 3.063) -- (3.750, 2.715) -- (3.800, 2.307) -- (3.850, 1.836) -- (3.900, 1.297) -- (3.950, 0.686) -- (4.000, 0.000);
		\fill[blue] (7.000, 0.000) -- (7.050, 0.215) -- (7.100, 0.418) -- (7.150, 0.611) -- (7.200, 0.792) -- (7.250, 0.964) -- (7.300, 1.126) -- (7.350, 1.278) -- (7.400, 1.421) -- (7.450, 1.555) -- (7.500, 1.681) -- (7.550, 1.798) -- (7.600, 1.907) -- (7.650, 2.008) -- (7.700, 2.102) -- (7.750, 2.188) -- (7.800, 2.268) -- (7.850, 2.341) -- (7.900, 2.408) -- (7.950, 2.468) -- (8.000, 2.522) -- (8.050, 2.571) -- (8.100, 2.614) -- (8.150, 2.652) -- (8.200, 2.685) -- (8.250, 2.713) -- (8.300, 2.737) -- (8.350, 2.755) -- (8.400, 2.770) -- (8.450, 2.781) -- (8.500, 2.787) -- (8.550, 2.790) -- (8.600, 2.790) -- (8.650, 2.785) -- (8.700, 2.778) -- (8.750, 2.767) -- (8.800, 2.754) -- (8.850, 2.737) -- (8.900, 2.718) -- (8.950, 2.696) -- (9.000, 2.672) -- (9.050, 2.645) -- (9.100, 2.615) -- (9.150, 2.584) -- (9.200, 2.550) -- (9.250, 2.514) -- (9.300, 2.476) -- (9.350, 2.436) -- (9.400, 2.394) -- (9.450, 2.350) -- (9.500, 2.305) -- (9.550, 2.257) -- (9.600, 2.208) -- (9.650, 2.157) -- (9.700, 2.104) -- (9.750, 2.050) -- (9.800, 1.993) -- (9.850, 1.935) -- (9.900, 1.875) -- (9.950, 1.814) -- (10.000, 1.750) -- (10.050, 1.685) -- (10.100, 1.618) -- (10.150, 1.549) -- (10.200, 1.477) -- (10.250, 1.404) -- (10.300, 1.329) -- (10.350, 1.251) -- (10.400, 1.172) -- (10.450, 1.090) -- (10.500, 1.005) -- (10.550, 0.918) -- (10.600, 0.828) -- (10.650, 0.736) -- (10.700, 0.640) -- (10.750, 0.542) -- (10.800, 0.440) -- (10.850, 0.336) -- (10.900, 0.227) -- (10.950, 0.116) -- (11.000, 0.000);
		\fill[purple] (0.000, 0.000) -- (0.050, 0.202) -- (0.100, 0.376) -- (0.150, 0.525) -- (0.200, 0.651) -- (0.250, 0.754) -- (0.300, 0.838) -- (0.350, 0.903) -- (0.400, 0.951) -- (0.450, 0.983) -- (0.500, 1.002) -- (0.550, 1.008) -- (0.600, 1.003) -- (0.650, 0.988) -- (0.700, 0.965) -- (0.750, 0.934) -- (0.800, 0.897) -- (0.850, 0.855) -- (0.900, 0.809) -- (0.950, 0.760) -- (1.000, 0.710) -- (1.050, 0.658) -- (1.100, 0.606) -- (1.150, 0.554) -- (1.200, 0.504) -- (1.250, 0.456) -- (1.300, 0.411) -- (1.350, 0.369) -- (1.400, 0.331) -- (1.450, 0.297) -- (1.500, 0.269) -- (1.550, 0.245) -- (1.600, 0.227) -- (1.650, 0.215) -- (1.700, 0.210) -- (1.750, 0.210) -- (1.800, 0.217) -- (1.850, 0.231) -- (1.900, 0.251) -- (1.950, 0.278) -- (2.000, 0.312) -- (2.050, 0.352) -- (2.100, 0.398) -- (2.150, 0.450) -- (2.200, 0.508) -- (2.250, 0.572) -- (2.300, 0.641) -- (2.350, 0.714) -- (2.400, 0.792) -- (2.450, 0.873) -- (2.500, 0.958) -- (2.550, 1.045) -- (2.600, 1.133) -- (2.650, 1.223) -- (2.700, 1.314) -- (2.750, 1.403) -- (2.800, 1.492) -- (2.850, 1.578) -- (2.900, 1.661) -- (2.950, 1.739) -- (3.000, 1.812) -- (3.050, 1.878) -- (3.100, 1.937) -- (3.150, 1.987) -- (3.200, 2.026) -- (3.250, 2.054) -- (3.300, 2.068) -- (3.350, 2.068) -- (3.400, 2.052) -- (3.450, 2.019) -- (3.500, 1.967) -- (3.550, 1.893) -- (3.600, 1.797) -- (3.650, 1.677) -- (3.700, 1.531) -- (3.750, 1.357) -- (3.800, 1.154) -- (3.850, 0.918) -- (3.900, 0.648) -- (3.950, 0.343) -- (4.000, 0.000);
		\fill[purple] (7.000, 0.000) -- (7.050, 0.107) -- (7.100, 0.209) -- (7.150, 0.305) -- (7.200, 0.396) -- (7.250, 0.482) -- (7.300, 0.563) -- (7.350, 0.639) -- (7.400, 0.711) -- (7.450, 0.778) -- (7.500, 0.840) -- (7.550, 0.899) -- (7.600, 0.953) -- (7.650, 1.004) -- (7.700, 1.051) -- (7.750, 1.094) -- (7.800, 1.134) -- (7.850, 1.171) -- (7.900, 1.204) -- (7.950, 1.234) -- (8.000, 1.261) -- (8.050, 1.286) -- (8.100, 1.307) -- (8.150, 1.326) -- (8.200, 1.343) -- (8.250, 1.357) -- (8.300, 1.368) -- (8.350, 1.378) -- (8.400, 1.385) -- (8.450, 1.390) -- (8.500, 1.394) -- (8.550, 1.395) -- (8.600, 1.395) -- (8.650, 1.393) -- (8.700, 1.389) -- (8.750, 1.384) -- (8.800, 1.377) -- (8.850, 1.369) -- (8.900, 1.359) -- (8.950, 1.348) -- (9.000, 1.336) -- (9.050, 1.322) -- (9.100, 1.308) -- (9.150, 1.292) -- (9.200, 1.275) -- (9.250, 1.257) -- (9.300, 1.238) -- (9.350, 1.218) -- (9.400, 1.197) -- (9.450, 1.175) -- (9.500, 1.152) -- (9.550, 1.129) -- (9.600, 1.104) -- (9.650, 1.078) -- (9.700, 1.052) -- (9.750, 1.025) -- (9.800, 0.997) -- (9.850, 0.968) -- (9.900, 0.938) -- (9.950, 0.907) -- (10.000, 0.875) -- (10.050, 0.842) -- (10.100, 0.809) -- (10.150, 0.774) -- (10.200, 0.739) -- (10.250, 0.702) -- (10.300, 0.664) -- (10.350, 0.626) -- (10.400, 0.586) -- (10.450, 0.545) -- (10.500, 0.502) -- (10.550, 0.459) -- (10.600, 0.414) -- (10.650, 0.368) -- (10.700, 0.320) -- (10.750, 0.271) -- (10.800, 0.220) -- (10.850, 0.168) -- (10.900, 0.114) -- (10.950, 0.058) -- (11.000, 0.000);
	\end{tikzpicture}
	\begin{tikzpicture}[scale=0.85]
		\node at (5.5, 4.5) {\large Wasserstein Interpolation};
		\node[red] at (0.5, 2.3) {$\mu$};
		\node[blue] at (9.5, 2.7) {$\nu$};
		\fill[red] (0.000, 0.000) -- (0.050, 0.403) -- (0.100, 0.752) -- (0.150, 1.051) -- (0.200, 1.302) -- (0.250, 1.509) -- (0.300, 1.676) -- (0.350, 1.806) -- (0.400, 1.902) -- (0.450, 1.967) -- (0.500, 2.004) -- (0.550, 2.016) -- (0.600, 2.006) -- (0.650, 1.976) -- (0.700, 1.929) -- (0.750, 1.868) -- (0.800, 1.794) -- (0.850, 1.710) -- (0.900, 1.618) -- (0.950, 1.521) -- (1.000, 1.419) -- (1.050, 1.315) -- (1.100, 1.211) -- (1.150, 1.108) -- (1.200, 1.008) -- (1.250, 0.912) -- (1.300, 0.822) -- (1.350, 0.738) -- (1.400, 0.662) -- (1.450, 0.595) -- (1.500, 0.537) -- (1.550, 0.490) -- (1.600, 0.455) -- (1.650, 0.431) -- (1.700, 0.419) -- (1.750, 0.420) -- (1.800, 0.435) -- (1.850, 0.462) -- (1.900, 0.503) -- (1.950, 0.556) -- (2.000, 0.623) -- (2.050, 0.703) -- (2.100, 0.796) -- (2.150, 0.900) -- (2.200, 1.017) -- (2.250, 1.144) -- (2.300, 1.281) -- (2.350, 1.428) -- (2.400, 1.584) -- (2.450, 1.746) -- (2.500, 1.915) -- (2.550, 2.089) -- (2.600, 2.267) -- (2.650, 2.447) -- (2.700, 2.627) -- (2.750, 2.807) -- (2.800, 2.984) -- (2.850, 3.156) -- (2.900, 3.321) -- (2.950, 3.478) -- (3.000, 3.624) -- (3.050, 3.757) -- (3.100, 3.874) -- (3.150, 3.973) -- (3.200, 4.052) -- (3.250, 4.107) -- (3.300, 4.136) -- (3.350, 4.137) -- (3.400, 4.105) -- (3.450, 4.038) -- (3.500, 3.933) -- (3.550, 3.787) -- (3.600, 3.595) -- (3.650, 3.355) -- (3.700, 3.063) -- (3.750, 2.715) -- (3.800, 2.307) -- (3.850, 1.836) -- (3.900, 1.297) -- (3.950, 0.686) -- (4.000, 0.000);
		\fill[blue] (7.000, 0.000) -- (7.050, 0.215) -- (7.100, 0.418) -- (7.150, 0.611) -- (7.200, 0.792) -- (7.250, 0.964) -- (7.300, 1.126) -- (7.350, 1.278) -- (7.400, 1.421) -- (7.450, 1.555) -- (7.500, 1.681) -- (7.550, 1.798) -- (7.600, 1.907) -- (7.650, 2.008) -- (7.700, 2.102) -- (7.750, 2.188) -- (7.800, 2.268) -- (7.850, 2.341) -- (7.900, 2.408) -- (7.950, 2.468) -- (8.000, 2.522) -- (8.050, 2.571) -- (8.100, 2.614) -- (8.150, 2.652) -- (8.200, 2.685) -- (8.250, 2.713) -- (8.300, 2.737) -- (8.350, 2.755) -- (8.400, 2.770) -- (8.450, 2.781) -- (8.500, 2.787) -- (8.550, 2.790) -- (8.600, 2.790) -- (8.650, 2.785) -- (8.700, 2.778) -- (8.750, 2.767) -- (8.800, 2.754) -- (8.850, 2.737) -- (8.900, 2.718) -- (8.950, 2.696) -- (9.000, 2.672) -- (9.050, 2.645) -- (9.100, 2.615) -- (9.150, 2.584) -- (9.200, 2.550) -- (9.250, 2.514) -- (9.300, 2.476) -- (9.350, 2.436) -- (9.400, 2.394) -- (9.450, 2.350) -- (9.500, 2.305) -- (9.550, 2.257) -- (9.600, 2.208) -- (9.650, 2.157) -- (9.700, 2.104) -- (9.750, 2.050) -- (9.800, 1.993) -- (9.850, 1.935) -- (9.900, 1.875) -- (9.950, 1.814) -- (10.000, 1.750) -- (10.050, 1.685) -- (10.100, 1.618) -- (10.150, 1.549) -- (10.200, 1.477) -- (10.250, 1.404) -- (10.300, 1.329) -- (10.350, 1.251) -- (10.400, 1.172) -- (10.450, 1.090) -- (10.500, 1.005) -- (10.550, 0.918) -- (10.600, 0.828) -- (10.650, 0.736) -- (10.700, 0.640) -- (10.750, 0.542) -- (10.800, 0.440) -- (10.850, 0.336) -- (10.900, 0.227) -- (10.950, 0.116) -- (11.000, 0.000);
		\fill[purple] (3.500, 0.000) -- (3.550, 0.279) -- (3.600, 0.526) -- (3.650, 0.758) -- (3.700, 0.977) -- (3.750, 1.171) -- (3.800, 1.343) -- (3.850, 1.500) -- (3.900, 1.643) -- (3.950, 1.768) -- (4.000, 1.874) -- (4.050, 1.965) -- (4.100, 2.041) -- (4.150, 2.103) -- (4.200, 2.151) -- (4.250, 2.184) -- (4.300, 2.202) -- (4.350, 2.206) -- (4.400, 2.196) -- (4.450, 2.172) -- (4.500, 2.133) -- (4.550, 2.078) -- (4.600, 2.009) -- (4.650, 1.923) -- (4.700, 1.819) -- (4.750, 1.696) -- (4.800, 1.582) -- (4.850, 1.413) -- (4.900, 1.279) -- (4.950, 1.102) -- (5.000, 1.030) -- (5.050, 0.804) -- (5.100, 0.828) -- (5.150, 0.838) -- (5.200, 0.760) -- (5.250, 0.925) -- (5.300, 1.088) -- (5.350, 1.157) -- (5.400, 1.422) -- (5.450, 1.538) -- (5.500, 1.746) -- (5.550, 1.912) -- (5.600, 2.060) -- (5.650, 2.209) -- (5.700, 2.342) -- (5.750, 2.459) -- (5.800, 2.564) -- (5.850, 2.656) -- (5.900, 2.736) -- (5.950, 2.805) -- (6.000, 2.862) -- (6.050, 2.908) -- (6.100, 2.944) -- (6.150, 2.969) -- (6.200, 2.985) -- (6.250, 2.989) -- (6.300, 2.984) -- (6.350, 2.970) -- (6.400, 2.948) -- (6.450, 2.919) -- (6.500, 2.874) -- (6.550, 2.821) -- (6.600, 2.761) -- (6.650, 2.700) -- (6.700, 2.620) -- (6.750, 2.525) -- (6.800, 2.430) -- (6.850, 2.336) -- (6.900, 2.211) -- (6.950, 2.080) -- (7.000, 1.955) -- (7.050, 1.814) -- (7.100, 1.644) -- (7.150, 1.485) -- (7.200, 1.317) -- (7.250, 1.113) -- (7.300, 0.921) -- (7.350, 0.715) -- (7.400, 0.477) -- (7.450, 0.255) -- (7.500, 0.000);
	\end{tikzpicture}
\end{center}

What emerges from those two interpolations is that the Wasserstein distance
seems particularily well suited to manipulate distributions, as it appears
to take into account the specificities (like modes, shape, etc) of both
the source and the target distribution, and the resulting barycenter looks
like a distribution combining those into one distribution, while the $l^2$
barycenter does not merge those specificities into one distribution but
rather renormalize the source and target distributions.

We can extend this idea to the computation of the barycenter of an arbitrary
number of distributions. Formally, the computing the barycenter $\mu$ of $N$
distributions $\nu_i$ weighted by the $\lambda_i$ boils down to the following
minimization problem:

$$ \min_{\mu \in \mathcal{P}(\Omega)} \sum_{i=1}^N \lambda_i W_p^p(\mu,
\nu_i) $$

Now we can observe what the barycenter looks like with $4$ distributions
(seen as images) on $\mathbf{R}^2$ in the \figurename~\ref{shp1}.

\begin{figure}[h]
	\centering \includegraphics[scale=0.4]{wasserstein_bar.png}
	\captionsetup{justification=centering} \caption{Each image contains
	several barycenters of the four shapes that are in the corners}
	\label{shp1}
\end{figure}

\sect{How to compute Optimal Transport?}

Now that we have a convenient formulation of the optimal transport problem,
we can study how to effectively compute minimizers of the optimal transport
problem. For this we will introduce several new formulation, more adapted
to effective solving. Sometimes, it is worth noting that we are only interested
in computing the Wasserstein distance between two distributions, rather than
the actual transport map.

\subs{Duality}

To effectively solve the optimal transport problem, we embrace the setting
of discrete spaces. In this setting, probability measures can be seen as a
sum of diracs impulses.

$$ \mu = \sum_{i=1}^n a_i \delta_{x_i} \qquad \nu = \sum_{j =1}^m b_j \delta_{y_j} $$

The cost function is a matrix $D \in \R_+^{n \times m}$ such that $D_{ij}
= d(x_i, y_j)^p$. Our joint distribution $P$ is also a matrix of $\R_+^{n
\times m}$ that has to satisfy several constraints that can be expressed
matricially: if we denote by $a$ and $b$ the vector of the coefficients of
the Dirac decompositions of, the set which $P$ has to belong to is:

$$ U(a, b) = \left\{ P \in \R_+^{n \times m}~|~P \mathbf{1}_m = a, \, P^\trans \mathbf{1}_n = b \right\} $$

\DEF{
    The Wasserstein distance in a discrete space is defined as:
	$$ W_p^p(\mu, \nu) = \min_{P \in U(a, b)} \langle P, D \rangle $$
	\vspace{-6mm}
}

\paragraph{Dual} We now focus on the dual form of this optimization
problem. For this we introduce the Lagrangian, using the Lagrange multipliers
$\alpha$ and $\beta$

$$
    L(P, \alpha, \beta) = \langle P, D \rangle + \alpha^\trans (a - P \mathbf{1}_m) + \beta^\trans (b - P^\trans \mathbf{1}_n)
$$

As usual in a Lagrangian formulation, the objective function of the dual
problem is:

$$ g(\alpha, \beta) = \min_{P \geqslant 0} L(P, \alpha, \beta) = \min_{P \geqslant 0} \alpha^\trans a + \beta^\trans b + \langle P, D - \alpha \mathbf{1}_m^\trans - \mathbf{1}_n \beta^\trans \rangle $$

If the matrix $D - \alpha \mathbf{1}_m^\trans - \mathbf{1}_n \beta^\trans$
has a negative coefficient, then by having the corresponding coefficient
of $P$ grow toward $+\infty$ we obtain a minimum of $-\infty$. But
if all the coefficients are non negative, then  $\langle P, D - \alpha
\mathbf{1}_m^\trans - \mathbf{1}_n \beta^\trans \rangle$ is non negative
and we just have to take $P=0$ to obtain a non zero value. We therefore obtain:

$$ g(\alpha, \beta) = \left\{ \begin{array}{ll}
\alpha^\trans a + \beta^\trans b & \text{si } D - \alpha \mathbf{1}_m^\trans - \mathbf{1}_n \beta^\trans \geqslant 0 \\
-\infty & \text{sinon}
\end{array}\right. $$

Finally, the dual problem is the maximization of this function $g$.

\DEF{
	The \textbf{dual} of the optimal transport problem is:
	$$ W_p^p(\mu, \nu) = \max_{\alpha \in \R^n, \, \beta \in \R^m \atop \alpha_i + \beta_j \leqslant D(x_i, y_j)^p} \alpha^\trans a + \beta^\trans b $$
	\vspace{-5mm}
}

We have reduced our initial problem into a linear programming
formulation. Using a minimum flow solver, we can solve this linear optimization
problem in $\mathcal{O}(n^3 \log (n))$. But the solution is not stable,
as illustrated on the following figure. If we slightly modify our distance
$D$ or if we change the source and destination measures, the value of $P$
can drastically change, since $P$ is a vertex of our simplex. One solution
is to regularize the problem to fall back on optimizing in a set $U_\alpha(a,
b)$ strictly convex. This set is strictly contained in $U(a, b)$ and the
optimal solution of this new problem will not necessarily be optimal for the
initial problem, but will remain valid.

We will introduce in the next section a regularization of the original
problem, that will us to exhibit an iterative algorithm that converges toward
a meaningful approximation of the minimizer, as well as mainly relying on
matrix-product kind of linear algebrea and thus potentially implemented
on GPUs.

\begin{center}
	\begin{tikzpicture}[scale=20, >={latex}]
		\clip (0.2, -0.01) rectangle (0.51, 0.2);
		\draw[blue, thick] (0.1420, 0.1407) -- (0.5970, -0.1407);
		\draw[black, ->, thick] (0.2038, 0.1216) -- (0.2507, 0.1975);
		\fill[brown!40] (0.4503, 0.1444) -- (0.2251, 0.1444) -- (0.3695, 0.0000) -- (0.4503, -0.0000);
		\fill[greenTikz!60] (0.3827, 0.0946) -- (0.3827, 0.1104) -- (0.3804, 0.1148) -- (0.3759, 0.1206) -- (0.3692, 0.1263) -- (0.3602, 0.1307) -- (0.3556, 0.1321) -- (0.3489, 0.1336) -- (0.3264, 0.1336) -- (0.3219, 0.1321) -- (0.3151, 0.1278) -- (0.3129, 0.1234) -- (0.3129, 0.1191) -- (0.3151, 0.1133) -- (0.3241, 0.1018) -- (0.3444, 0.0888) -- (0.3534, 0.0859) -- (0.3714, 0.0859) -- (0.3804, 0.0917);
		\node[blue] at (0.3444, 0.0888) {$\bullet$};
		\node[blue, below=2] at (0.3444, 0.0888) {$P_\alpha$};
		\node[greenTikz] at (0.3489, 0.1119) {$\bullet$};
		\node[red] at (0.3695, 0.0000) {$\bullet$};
		\node[red, above=2] at (0.3695, 0) {$P$};
		\node at (0.482, 0.08) {$U(a, b)$};
		\node at (0.413, 0.12) {$U_\alpha(a, b)$};
		\node at (0.213, 0.165) {$D$};
	\end{tikzpicture}
\end{center}

\subs{Entropic Regularization}

The regularization that we highlight consists in solving the optimal
transport problem, while maximizing the entropy of the joint-probability
$P$. We therefore exhibit a new parameter $\gamma$ that parametrizes the
regularization and we obtain the following distance.

\DEF{
	The \textbf{regularized Wasserstein distance} is defined as follows:
	$$ W_\gamma(\mu, \nu) = \min_{P \in U(a, b)} \langle P, D \rangle - \gamma H(P) $$
	\vspace{-5mm}
} 

\paragraph{Remark}
Recall that we can consider two random variables $X$ and $Y$ such that $X \sim
\mu$, $Y \sim \nu$ and consider their joint distribution $P$ such that $(X,Y)
\sim P$. The entropy of $P$ is maximal when $X$ and $Y$ are independant,
\emph{i.e.} when $P$ factorizes as $P = ab^\trans$ and this maximum entropy
is given by $H(\mu) + H(\nu)$. The regularization therefore produces a
matrix whose positive values are more distributed. In other words, we favor
randomness of the transport map against determinism. The intuition behind
this regularization comes from the observation that actual trafic patterns
in networks are sparser than the theoretical solution obtained through
a minimizer of the Kantorovich problem.

\begin{center}
	\includegraphics[scale=0.25]{reg_wass.png}
\end{center}

By a strict convexity argument, there exist a unique matrix $P_\gamma$
minimizing the distance:
$$ P_\gamma = \argmin_{P \in U(a, b)} \langle P, D \rangle - \gamma H(P) $$

\PROP{
    There exist a unique couple of vectors $u$ and $v$ belonging to
    $\R_+^n$ and $\R_+^m$ such that:
	$$ P_\gamma = \text{diag}(u) K \text{diag}(v), \qquad K = e^{-D / \gamma} $$
	\vspace{-6mm}
}

\dem

We write the Laplacian of our new optimization problem.

$$ L(P, \alpha, \beta) = \sum_{ij} \left( P_{ij} D_{ij} + \gamma P_{ij} \left( \log_2 P_{ij} - 1 \right) \right) + \alpha^\trans (a - P \mathbf{1}_m) + \beta^\trans (b - P^\trans \mathbf{1}_n) $$

We compute the partial derivative with respect to each $P_{ij}$
$$ \dfrac{\partial L}{\partial P_{ij}} = D_{ij} + \gamma \log_2 P_{ij} - \alpha_i - \beta_j $$

The dual problem is the maximization of the minimum of the Laplacian with
respect to $P$. We must look for $P$ such that the partial derivative is
equal to zero:

$$ \dfrac{\partial L}{\partial P_{ij}} = 0 \Rightarrow P_{ij} = e^{\frac{\alpha_i}{\gamma}} e^{-\frac{D_{ij}}{\gamma}}  e^{\frac{\beta_j}{\gamma}} = u_i K_{ij} v_j $$

\findem

\paragraph{Sinkhorn}
We can derive an iterative method to find this matrix $P_\gamma$. We use
the condition $P_\gamma \in U(a,b)$:

$$ P_\gamma \in U(a, b) \Leftrightarrow \left\{ \begin{array}{lrr}
\text{diag}(u) K \text{diag}(v) \mathbbm{1}_m & = & a \\
\text{diag}(v) K^\trans \text{diag}(u) \mathbbm{1}_n & = & b
\end{array} \right. $$

$$ P_\gamma \in U(a, b) \Leftrightarrow \left\{ \begin{array}{lrr}
\text{diag}(u) K v & = & a \\
\text{diag}(v) K^\trans u & = & b
\end{array} \right. $$

Then, by introducing $\odot$ the coefficient-wise product, we can rewrite
this as

$$ P_\gamma \in U(a, b) \Leftrightarrow \left\{ \begin{array}{lrr}
u \odot K v & = & a \\
v \odot K^\trans u & = & b
\end{array} \right. $$

We end up considering a problem which was already studied in the numerical
analysis community, and known as the \emph{matrix scaling problem}. From
this formulation, rewritten as below using the coefficient-wise division
$\oslash$, we can obtain an iterative algorithm performing Sinkhorn's updates.

$$ P_\gamma \in U(a, b) \Leftrightarrow \left\{ \begin{array}{lrc}
u & = & a \oslash K v \\
v & = & b \oslash K^\trans u
\end{array} \right. $$

First we modify $u$ such that it satisfies the first equation, and we then
use this value to modify the value of $v$ in order for it to satisfy the
second. And we keep performing those updates until convergence. Sinkhorn's
algorithm is thus the following: \\

\begin{algorithm}
    \caption{Sinkhorn}
    \Repeat{convergence of $u, v$}{
        $u \gets a \oslash K v$ \;
        $v \gets b \oslash K^\trans u$ \;
    }
\end{algorithm}

\paragraph{Complexity}
It has been proved that the algorithm is a linear convergence scheme. Moreover,
an iteration is naively done in $\mathcal{O}(mn)$ but the computation can
easily be parallelized, and especially performed on GPUs, the bottleneck of one
update being the two matrix products $Kv$ and $K^\trans u$. It is also
possible to use grid convolution to obtain a complexity of $\mathcal{O}(n
\log n)$ for one update. More practical precise and exhaustive details can
be found in Gabriel Peyré and Marco Cuturi's \emph{Computational Optimal
Transport} \cite{Peyr2018ComputationalOT}.

\paragraph{Dual}

One can also notice the formulation of the dual thanks to the Proposition 1.
$$ W_\gamma(\mu, \nu) = \max_{\alpha, \beta} \alpha^\trans a + \beta^\trans b - \gamma \left( e^{\alpha / \gamma} \right)^\trans K \left( e^{\beta / \gamma} \right) $$

\paragraph{Link with the KL divergence}
Writing the kernel:

$$ K_\gamma(i, j) = \exp \left( - \dfrac{d_{i, j}}{\gamma} \right) $$

We obtain a new formulation of the entropic regularized problem using the
KL-divergence

$$ W_\gamma(\mu, \nu) = \min_{P \in U(a, b)} \gamma KL(P | K_\gamma) $$

\sect{Optimal Transport and Machine Learning}

Now that we have convinced ourselves of the good mathematical foundations
of Optimal Transport, and of the fact that we can actually compute it to
some extent, we can wonder how we can put this tool to use in the setting
of machine learning.

\subs{What do we want to optimally transport ?}

In the previous section we have seen that we have at our disposal an
algorithm to compute optimal transport maps (Sinkhorn's algorithm), and that
this algorithm can be parallelized. We can take advantage of this fact to
actually compute optimal transport among huge databases. Since computing
optimal transport maps implies that we can compute a meaningful distance
between two objects, as long as they can be interpreted as distributions,
one of the application of this is similarity based retrieval.

\paragraph{Color histograms}

The color-histogram of an image is a tool that characterizes the
distribution of colors of an image. Interestingly enough, it has been noticed
that color-histograms are a good tool to describe the similarity of two
images. Since we now have a tool to compute the distance between two
distribution probability, we can apply it to histograms (that are essentially
discretized distribution, so much so that the algorithms and methods that
we described earlier are relevant even without any fondamental change of
setting). For a given image we can therefore compute the distance between its
histogram and the histogram of images comming from a bigger database: picking
images that have the most similar histogram (in the sense of the Wasserstein
distance) will therefore allow to perform some form of similarity based
image retrieval.

\begin{center}
	\includegraphics[scale=0.3]{image_histo.png}
    \captionof{figure}{Two images and their respective color-histograms,
    embedded in $\R^2$ (Image from Marco Cuturi's Primer on Optimal Transport at
    NIPS 2017)}
\end{center}


\paragraph{Cloud of word}

We can apply the same technique as before, but instead of considering
color-histograms, we can try to find some kind of distribution coming from
other kind of documents, for example text documents. Some previous work,
such as the $\texttt{word2vec}$ framework allows for the embedding of
natural language words into an Euclidean space. A text (seen as a collection
of words) therefore somehow defines a probability distribution over this
embedded space. As for images we can then compare this distribution to
the distributions of other texts coming from a database (still in the
sense of Wasserstein distance), and hopefully retrieve text dealing with
similar topics, although there may be some significant differences in the
actual vocabulary of those texts. We can take advantage of the geometry of the
distribution of probability in the embedded text space, that tries to ensure
that similar distributions are coming from texts dealing with similar topics.

\subs{Wassersteinization}

We can go further than just using the Wasserstein to compute distance between
distributions and use this notion as distance as a main tool for already
existing machine learning problems (we previously emphasized retrieval
tasks for instance) by introducing the Wasserstein distance on well studied
machine learning settings and problems. We therefore shed a new light on those
problems, and the results are often fruitful. Some authors have coined the
term $\textbf{Wassersteinization}$ to describe this process.

\DEF{
	$\textbf{Wassersteinization}$ is the process of introducing optimal
	transport into an optimization or machine learning problem
} 

One way to approach Wassersteinization is to introduce Wasserstein distance
as a loss or fidelity term in optimization problems. This will motivate
the interest toward not only the very Wasserstein distance, but also its
derivative. More precisely one can show that we can computationaly evaluate
the derivatives of the Wasserstein distance. Therefore we can deal with it
in a variety of optimization problems, including machine lerning related ones.

\paragraph{Averaging data}

We can also see optimal transport as a normalization tool for data. One of
the setting where this point of view as been proposed is the one of data
averaging. We have already discussed earlier the benefits of Wasserstein
barycenters when compared to, say, linear interpolations or $l^2$
barycenters. One can put this in good use in the case of data acquired through
real world experiment. For instance, we can imagine a neuro-imagery setting,
where the goal is to study the reaction of the brain of a patient to a
certain precise stimulus. To do this we subjet the patient to the stimuli
several time and we aim to submit the measures of the brain activity to
a machine algorithm to study some of its features. But because of the huge
variety of data acquisition hazards (noise, imprecisions in the measures,
patient variability etc), the result will slighty differ from one experiment
to another although it concerns the same stimulus. Therefore computing the
average of the brain activity (that can easily seen to be an analog of a
probability distribution on the brain space) in the sense of Wasserstein
barycenters can hopefully give access to more relevant data, without loosing
the meaningful information.

\begin{center}
    \centering
	\includegraphics[scale=0.3]{brain_map.png}
    \captionof{figure}{On the left the standard average brain map among
    several experiments, on the right the Wasserstein average of the same
    brain activity data. (Image from \cite{gramfort2015fast}) }
\end{center}

\paragraph{Aggregating distributions}

Instead of processing the input of our machine learning algorithms, one can
use this idea of aggregating several distribution on the output of machine
learning algorithms. Imagine that we want to use Bayesian learning (\emph{ie.}
learn a probability distribution, in a Bayesian framework), on a dataset so
huge that it cannot even fit on a single machine, and would it fit that the
computation time would be out of reach. We can imagine to split the dataset
into $J$ different parts and distribute it amongst $J$ machines running
the same learning algorithms. The result of this process is a set of $J$
distributions learned from each part of the dataset. Although they represent
the same truth, because of the variation of the data those distributions will
be slightly different. Once again Wasserstein-averaging provides a useful tool
to aggregate those distributions into an hopefully meaningful one, closer
to the underlying real distribution. The good news is that this Wasserstein
posterior aggregation method comes with theoretic statistical guaranties!

\paragraph{Semi-supervised learning and Wasserstein propagation}

We are interested in smoothing a graph $(V,E)$ where an histogram is associated
$\mu_v$ to each vertex $v$, with a susbset $S$ of the vertices that have a
fixed histogram (known data). To write this more formally, we want to solve
the following optimization problem:

$$
    \underset{\substack{\mu_i \in \mathcal{P}\left(\Omega\right) \\ \text{for }i \in V\setminus S}}\min \sum_{(e_1, e_2) \in E} W_2^2\left(\mu_{e_1}, \mu_{e_2}\right)
$$

That is, we want to propagate the distribution known at certain vertices
along the graph, with a "Wasserstein manner". It is a formulation of several
semi-suppervised learning problems, where we only have at our disposal the
structure of the graph, and information a small portion of the vertices. The
distribution that we are handling here can for instance be probability
distribution of belonging to each class, in a classification problem (which
leads us to solving the "stereotypical" semi-suppervised problem that is
vertice labelling), but we could consider broader classes of problems with
this formalism.

\subs{Wasserstein PCA and Geodesics}

The Wasserstein distance gives the space of probability measure a structure
of geodesic metric space. Moreover, it has been shown that when $\Omega$
is an Hilbert space, then the space of probability measures endowed
with the Wasserstein distance has a Riemannian manifold structure (see
\cite{ambrosio2008gradient}). Some authors such as \cite{seguy2015principal}
have proposed to take advantage of this structure to define the notion of
\textbf{Principal Geodesic Analysis} over this space, which aims to be an
analog of the good old Principal Component Analysis with Euclidean metrics.

The idea is that, as Ambrosio et al. shown in \cite{ambrosio2008gradient},
we can characterize the geodesic path between two distributions, that is
the shortest path with respect to the Wasserstein distance. We denote
$(\rho_{\mu_1 \to \mu_2}^t)_t$ the geodesic path between $\mu_1$ and $\mu_2$,
parametrized by $t$. Now, given a family of measures $\nu_1, \nu_2, \dots,
\nu_N$, we would like to compute the pricipal geodesics of this family, that
is find a set of geodesics between some measures (that also are to compute)
that passes through the Wasserstein iso-barycenter of the $\nu_i$ and that
are close to each of the $\nu_i$.

\begin{center}
    \begin{tikzpicture}[scale=0.7]
        % the bottom left border of the surface
        \path[name path=border1] (0,0) to[out=-10,in=150] (6,-2);
        % the upper right border of the surface
        \path[name path=border2] (12,1) to[out=150,in=-10] (5.5,3.2);
        % a path for a line crossing both borders
        \path[name path=redline] (0,-0.4) -- (12,1.5);
        % intersections between the borders and the lines
        \path[name intersections={of=border1 and redline,by={a}}];
        \path[name intersections={of=border2 and redline,by={b}}];

        % we draw the surface
        \shade[left color=whiteGray!90,right color=darkWhite!90] 
          (0,0) to[out=-10,in=150] (6,-2) -- (12,1) to[out=150,in=-10] (5.5,3.7) -- cycle;

        \coordinate (mu1) at (3.5,0.5);
        \coordinate (mu2) at (9,1);

        \draw[blue, fill=blue] (mu1) circle (2pt);
        \draw[blue] (mu1) node[left] {$\mu_1$};
        \draw[blue, fill=blue] (mu2) circle (2pt);
        \draw[blue] (mu2) node[right] {$\mu_2$};

        \draw [name path=geodesic, blue] (mu1) to[out=-20, in=-150] node[below] {$\left(\rho_{\mu_1 \to \mu_2}^t\right)_t$} coordinate[pos=0.093] (geo1) coordinate[pos=0.2] (geo2) coordinate[pos=0.53] (geo3) coordinate[pos=0.85] (geo4) (mu2) ;

        \coordinate (nu1) at (5,1.5);
        \coordinate (nu2) at (6.5,0.4);
        \coordinate (nu3) at (8,-0.5);
        \coordinate (nu4) at (4,0.2);

        \draw[red, dashed] (nu4) to (geo1);
        \draw[red, dashed] (nu1) to[out=-80, in=60] (geo2);
        \draw[red, dashed] (nu2) to[out=-80, in=70] (geo3);
        \draw[red, dashed] (nu3) to[out=70, in=-80] (geo4);
        \draw[red, fill=red] (nu1) circle (2pt) node[above] {$\nu_1$};
        \draw[red, fill=red] (nu2) circle (2pt) node[above] {$\nu_2$};
        \draw[red, fill=red] (nu3) circle (2pt) node[below] {$\nu_3$};
        \draw[red, fill=red] (nu4) circle (2pt) node[below] {$\nu_4$};

    \end{tikzpicture}
\end{center}

We can formalize this idea more precisely as follows, using for example the
second order Wasserstein distance $W_2^2$.

$$
    \min_{\mu_1, \mu_2 \in \mathcal{P}(\Omega)}
        \sum_{i=1}^N \min_t W_2^2\left(\rho_{\mu_1 \to \mu_2}^t, \nu_i\right)
$$

Since a couple of measures $(\mu_1, \mu_2)$ entirely characterizes a
geodesic path, our optimization is performed over the space of probability
measures over $\Omega$. This problem can be solved using the methods that
we presented earlier in our \emph{How to compute Optimal Transport} section,
and some projected gradient descent because of the overall non-convexity of
this problem. We can iterate this process to gradually explain more and more
features of our distributions.

\begin{center}
    \centering
	\includegraphics[scale=0.3]{ims/MNIST_PCA.png}
    \captionof{figure}{Principal Geodesic Components obtained from a subset
    of $2000$ images of the MNIST database, containing an equal proportion
    of \texttt{2} and \texttt{4}.(Image from \cite{seguy2015principal}) }
\end{center}
